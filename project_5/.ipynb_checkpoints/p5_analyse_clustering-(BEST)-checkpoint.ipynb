{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olist E-Commerce Website Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import r2_score, confusion_matrix\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions d'automatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take df, make copy, show info() and return the dataframe\n",
    "def copy_get_info_df(df):\n",
    "    new_df = df.copy()\n",
    "    new_df.info()\n",
    "    print('total missing values : ', new_df.insull().sum())\n",
    "    print('the shape is : ', new_df.shape)\n",
    "    return new_df\n",
    "#-------------------------------------------------------------------\n",
    "# pass list of dataframes and get all the infos, shape, missing values at once \n",
    "def get_all_df_info(dataframes):\n",
    "    df_names = ['customer data :','order items : ','order payments : ','order reviews :','orders : ','products : ','sellers : ','product translation :']\n",
    "    for name,df in zip(df_names,dataframes):\n",
    "        print('\\n INFORMATION ABOUT THE DATASET ', name,'\\n')\n",
    "        df.info()\n",
    "        print('Total missing values : ', df.isnull().sum())\n",
    "        print('Shape : ', df.shape)\n",
    "        print('\\n')\n",
    "#---------------------------------------------------------------------\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " INFORMATION ABOUT THE DATASET  customer data : \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      "customer_id                 99441 non-null object\n",
      "customer_unique_id          99441 non-null object\n",
      "customer_zip_code_prefix    99441 non-null int64\n",
      "customer_city               99441 non-null object\n",
      "customer_state              99441 non-null object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n",
      "Total missing values :  customer_id                 0\n",
      "customer_unique_id          0\n",
      "customer_zip_code_prefix    0\n",
      "customer_city               0\n",
      "customer_state              0\n",
      "dtype: int64\n",
      "Shape :  (99441, 5)\n",
      "\n",
      "\n",
      "\n",
      " INFORMATION ABOUT THE DATASET  order items :  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      "order_id               112650 non-null object\n",
      "order_item_id          112650 non-null int64\n",
      "product_id             112650 non-null object\n",
      "seller_id              112650 non-null object\n",
      "shipping_limit_date    112650 non-null object\n",
      "price                  112650 non-null float64\n",
      "freight_value          112650 non-null float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n",
      "Total missing values :  order_id               0\n",
      "order_item_id          0\n",
      "product_id             0\n",
      "seller_id              0\n",
      "shipping_limit_date    0\n",
      "price                  0\n",
      "freight_value          0\n",
      "dtype: int64\n",
      "Shape :  (112650, 7)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = [customers_dataset_df, order_items_df]\n",
    "get_all_df_info(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### customers_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      "customer_id                 99441 non-null object\n",
      "customer_unique_id          99441 non-null object\n",
      "customer_zip_code_prefix    99441 non-null int64\n",
      "customer_city               99441 non-null object\n",
      "customer_state              99441 non-null object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# no nulls values\n",
    "customers_dataset_df = pd.read_csv('./brazilian-ecommerce/olist_customers_dataset.csv')\n",
    "customers_dataset_df_clean = customers_dataset_df.copy()\n",
    "\n",
    "customers_dataset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b3160718b3f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcustomers_dataset_dfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcustomers_dataset_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "customers_dataset_dfname = [ k for k,v in locals().iteritems() if v == customers_dataset_df][0]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### order_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      "order_id               112650 non-null object\n",
      "order_item_id          112650 non-null int64\n",
      "product_id             112650 non-null object\n",
      "seller_id              112650 non-null object\n",
      "shipping_limit_date    112650 non-null object\n",
      "price                  112650 non-null float64\n",
      "freight_value          112650 non-null float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# no nulls\n",
    "\n",
    "order_items_df = pd.read_csv('./brazilian-ecommerce/olist_order_items_dataset.csv')\n",
    "order_items_df_clean = order_items_df.copy()\n",
    "\n",
    "order_items_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### order_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103886 entries, 0 to 103885\n",
      "Data columns (total 5 columns):\n",
      "order_id                103886 non-null object\n",
      "payment_sequential      103886 non-null int64\n",
      "payment_type            103886 non-null object\n",
      "payment_installments    103886 non-null int64\n",
      "payment_value           103886 non-null float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# no nulls\n",
    "order_payments_dataset_df = pd.read_csv('./brazilian-ecommerce/olist_order_payments_dataset.csv')\n",
    "order_payments_dataset_df_clean = order_payments_dataset_df.copy()\n",
    "\n",
    "order_payments_dataset_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### order_reviews_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      "review_id                  100000 non-null object\n",
      "order_id                   100000 non-null object\n",
      "review_score               100000 non-null int64\n",
      "review_comment_title       11715 non-null object\n",
      "review_comment_message     41753 non-null object\n",
      "review_creation_date       100000 non-null object\n",
      "review_answer_timestamp    100000 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# review_comment_title and review_comment_message fields are empty which is fine, we will not be using them in out analysis so\n",
    "# we will drop the columns in addition to review_creation_date and review_answer_timestamp columns\n",
    "order_reviews_dataset_df = pd.read_csv('./brazilian-ecommerce/olist_order_reviews_dataset.csv')\n",
    "order_reviews_dataset_df_clean = order_reviews_dataset_df.copy()\n",
    "\n",
    "order_reviews_dataset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-10b128d7a1de>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-10b128d7a1de>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    stop there\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stop there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop also review creation date and answer date we dont need those\n",
    "order_reviews_dataset_df_clean.drop(columns = ['review_comment_title','review_comment_message','review_creation_date','review_answer_timestamp'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_reviews_dataset_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_reviews_dataset_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_reviews_dataset_df_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### orders_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_dataset_df = pd.read_csv('./brazilian-ecommerce/olist_orders_dataset.csv')\n",
    "orders_dataset_df_clean = orders_dataset_df.copy()\n",
    "orders_dataset_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_dataset_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.we will be assessing if our estimation on the order_estimated_delivery_date is correct most of the time or not, so in this case\n",
    "# we will create a df that has only the timestamps and dates and we will be dropping this nan values to do so, that is so we \n",
    "# do not loose data for other operations from the original dataframe.\n",
    "# 2. we need to change  the data type of the dates to datetime.\n",
    "order_datetime_list = ['order_purchase_timestamp', 'order_approved_at',\\\n",
    "                       'order_delivered_carrier_date', 'order_delivered_customer_date',\\\n",
    "                       'order_estimated_delivery_date']\n",
    "\n",
    "\n",
    "orders_dataset_df_clean[order_datetime_list] = orders_dataset_df_clean[order_datetime_list].apply(pd.to_datetime, errors = 'coerce')\n",
    "orders_dataset_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now we have the datetime type\n",
    "orders_dataset_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking valid values for order_status\n",
    "orders_dataset_df_clean.order_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if for the delivered items we have all the timings, the invoiced only can have nan values it is fine for the dates variables.\n",
    "# we can see that we still have missing dates for already delivered orders, we can investigate closely in the company to see why we are missing these dates.\n",
    "\n",
    "orders_dataset_df_clean.query(\"order_status in 'delivered'\").isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the indexes of the columns that have a delivered order_status and a null order_approved_at because it does not make sense\n",
    "delivered_and_not_approved_indexes = orders_dataset_df_clean[orders_dataset_df_clean['order_approved_at'].isnull()].query(\"order_status in 'delivered'\").index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_dataset_df_clean.drop(inplace = True, index = delivered_and_not_approved_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_dataset_df_clean.query(\"order_status in 'delivered'\").isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### products_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_dataset_df = pd.read_csv('./brazilian-ecommerce/olist_products_dataset.csv')\n",
    "products_dataset_df_clean = products_dataset_df.copy()\n",
    "\n",
    "products_dataset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we will be dropping the rows that have missing product_category_name, product_name_lenght, product_description_lenght, product_photos_qty\n",
    "# which are 610 rows of 32951\n",
    "products_dataset_df_clean[products_dataset_df_clean['product_category_name'].isnull()].shape\n",
    "null_products_indexes = products_dataset_df_clean[products_dataset_df_clean['product_category_name'].isnull()].index\n",
    "products_dataset_df_clean.drop(inplace = True, index = null_products_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "print(products_dataset_df_clean.shape[0],products_dataset_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 row missing dimensions, we will drop it also since it has negligible effect on our analysis\n",
    "products_dataset_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_products_missing_g_indexes = products_dataset_df_clean[products_dataset_df_clean['product_weight_g'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_dataset_df_clean.drop(inplace = True, index = additional_products_missing_g_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_dataset_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_dataset_df_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sellers_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't have missing values !\n",
    "sellers_dataset_df = pd.read_csv('./brazilian-ecommerce/olist_sellers_dataset.csv')\n",
    "sellers_dataset_df_clean = sellers_dataset_df.copy()\n",
    "\n",
    "sellers_dataset_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### product_category_name_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_category_name_translation_df = pd.read_csv('./brazilian-ecommerce/product_category_name_translation.csv')\n",
    "product_category_name_translation_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a master dataframe, that has all the clean dataframes to get more insights when we want to visualize, model and predict\n",
    "master_df = orders_dataset_df_clean.copy()\n",
    "\n",
    "master_df = master_df.merge(customers_dataset_df_clean, on='customer_id', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.merge(order_reviews_dataset_df_clean, on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.merge(order_payments_dataset_df_clean, on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.merge(order_items_df_clean, on = 'order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.merge(products_dataset_df_clean, on = 'product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.merge(sellers_dataset_df_clean, on = 'seller_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Visualization\n",
    "\n",
    "#### In this section we will be answering inquiries using visualizations of data insights using univariable, bivariable and multivariable plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only have two columns having null values, order_delivered_carrier_date and order_delivered_customer_date  \n",
    "master_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(master_df.corr().round(2), xticklabels=master_df.corr().columns, yticklabels=master_df.corr().columns, cmap='Spectral', center=0, annot=True)\n",
    "\n",
    "plt.title('Corrélations entres les features', fontsize=22)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I prefer round all correlations > 0.5 and make them = 1 so we can identify more clearely what is going on \n",
    "corr_df = master_df.corr().round(2)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(abs(corr_df)>0.5 , xticklabels=master_df.corr().columns, yticklabels=master_df.corr().columns, cmap='Spectral', center=0, annot=True)\n",
    "\n",
    "plt.title('corrélations simplifié', fontsize=22)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "sns.regplot(x=master_df['product_weight_g'], y=master_df['freight_value'], scatter_kws={'alpha':0.7, 'color':'coral'},\\\n",
    "           line_kws={'color':'red'});\n",
    "\n",
    "plt.xlim(0, 30000)\n",
    "\n",
    "plt.title('Correlation entre le poids du produit et la valeur Fret', fontsize=22)\n",
    "plt.xlabel('Product Weight'.title(), fontsize=15)\n",
    "plt.ylabel('Freight Value'.title(), fontsize=15)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions for some features\n",
    "master_df.hist(figsize=(15,20), color='skyblue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariable Plots\n",
    "\n",
    "* Type de payements \n",
    "* Range des prix de payement \n",
    "* Villes qui achetent le plus \n",
    "* fréquence d'achat par categorie de produit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "payment_type_count_plot_df = master_df[['payment_type','customer_id']].groupby(['customer_id', 'payment_type']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clients prefer the use of Credit card clearely\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "sns.countplot(payment_type_count_plot_df['payment_type']);\n",
    "\n",
    "plt.title('What is the most frequent payment type?'.title() , fontsize=20);\n",
    "plt.ylabel('count'.title(), fontsize=14);\n",
    "plt.xlabel('payment type'.title(), fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payement value frequency\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "# we use .sum() because we have the same clients sometimes so we avoid noise and confusion\n",
    "min_order_payment_value = min(master_df.groupby('customer_id').sum().reset_index()['payment_value'])\n",
    "max_order_payment_value = max(master_df.groupby('customer_id').sum().reset_index()['payment_value'])\n",
    "\n",
    "bins= np.linspace(start=min_order_payment_value, stop=1400, num=50)\n",
    "plt.hist(x=(master_df.groupby('customer_id').sum().reset_index()['payment_value']), bins=bins,color='skyblue');\n",
    "\n",
    "plt.title('payment value distribution per customer'.title() , fontsize=20);\n",
    "plt.ylabel('count'.title(), fontsize=14, rotation=90);\n",
    "plt.xlabel('payment value'.title(), fontsize=14);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customer_state_count_df = master_df.groupby(['customer_id','customer_state']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "sns.countplot(customer_state_count_df.customer_state, order=customers_dataset_df.customer_state.value_counts().index);\n",
    "\n",
    "plt.title('Most frequent customer state'.title(), fontsize=20);\n",
    "plt.ylabel('count'.title(), fontsize=14);\n",
    "plt.xlabel('customer state'.title(), fontsize=14);\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the translated product name category to the data_frame to use it in the following plots.\n",
    "master_df_with_product_categories = master_df.merge(product_category_name_translation_df, how='left', on='product_category_name');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "sns.countplot(master_df_with_product_categories.product_category_name_english,#\n",
    "              order=master_df_with_product_categories.product_category_name_english.value_counts().index)\n",
    "\n",
    "plt.title('Most in demand product category'.title(), fontsize=20);\n",
    "plt.ylabel('count'.title(), fontsize=14);\n",
    "plt.xlabel('product category'.title(), fontsize=14);\n",
    "\n",
    "plt.xticks(rotation=90, fontsize=10);\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariable plots\n",
    "\n",
    "* Mean score vs products category (Bar plot)\n",
    "* Mean score vs city (Bar plot)\n",
    "* Order Price vs Freight Price (Scatter plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_score_vs_cat_df = master_df_with_product_categories.groupby(['product_category_name_english']).mean()['review_score'].reset_index()\n",
    "mean_score_vs_cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The on average the best product category rating wise is that of cds_dvds_musicals, and the securit_and_services seems to have\n",
    "# the lowest rating.\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "sns.barplot(data = master_df_with_product_categories, x='product_category_name_english', y='review_score',\n",
    "            order = mean_score_vs_cat_df.sort_values('review_score', ascending=False)['product_category_name_english'].values\n",
    "            ,errcolor = 'grey')\n",
    "\n",
    "plt.title('Most highly rated product category'.title(), fontsize=20);\n",
    "plt.ylabel('Average Review Score'.title(), fontsize=14);\n",
    "plt.xlabel('Product Category'.title(), fontsize=14);\n",
    "\n",
    "plt.xticks(rotation=90, fontsize= 10);\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nicest state ?\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "sns.barplot(data = master_df_with_product_categories, x='customer_state', y='review_score',\\\n",
    "           order = master_df_with_product_categories.groupby('customer_state').mean()\\\n",
    "            .reset_index().sort_values('review_score', ascending=False)['customer_state'].values,\n",
    "           errcolor = 'grey');\n",
    "\n",
    "\n",
    "plt.title('Best reviews by states'.title(), fontsize=20);\n",
    "plt.ylabel('Average Review Score'.title(), fontsize=14);\n",
    "plt.xlabel('customer state'.title(), fontsize=14);\n",
    "\n",
    "plt.xticks(rotation=0, fontsize= 12);\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# relationship between the price of the order and the price of the freight?\n",
    "\n",
    "payment_vs_freight_df = master_df_with_product_categories.groupby('customer_id').sum().reset_index()[['payment_value','freight_value']]\n",
    "payment_vs_freight_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "sns.regplot(data=payment_vs_freight_df, x=payment_vs_freight_df.payment_value, y=payment_vs_freight_df.freight_value,\n",
    "            scatter_kws={'alpha':0.7, 'color':'skyblue'}, line_kws={'color':'red'});\n",
    "plt.xlim(0,20000);\n",
    "\n",
    "plt.title('Correlation between Payment and Freight value'.title(), fontsize=20);\n",
    "plt.ylabel('Freight value'.title(), fontsize=14);\n",
    "plt.xlabel('Payment Value'.title(), fontsize=14);\n",
    "\n",
    "plt.xticks(rotation=0, fontsize= 12);\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariable Plots\n",
    "* Payment value vs. month vs. year\n",
    "* we want to see the Evolution over time to understand better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_with_product_categories['year'] = pd.DatetimeIndex(master_df_with_product_categories['order_purchase_timestamp']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_with_product_categories['month'] = pd.DatetimeIndex(master_df_with_product_categories['order_purchase_timestamp']).month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_with_product_categories.groupby(['year','month']).sum()['payment_value'] #extremely powerful groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariable_plot_df = master_df_with_product_categories.groupby(['year','month']).sum()['payment_value'].reset_index()\n",
    "multivariable_plot_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=multivariable_plot_df, row = 'year', height=7, aspect=2.5, sharey=True)\n",
    "\n",
    "g = g.map(plt.bar, 'month', 'payment_value', color='skyblue')\n",
    "g.set_titles( size=20);\n",
    "g.set_ylabels('Payment Value'.title(), size=14);\n",
    "g.set_xlabels('months'.title(), size=14);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering ( creation de nouvelles features pour aider l'algorithme de clustering ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_with_product_categories['order_delivered_customer_date'].fillna(method='bfill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "master_df1  = master_df_with_product_categories.copy()\n",
    "# 3 features : order_status, customer_state, payment_type\n",
    "master_df1['order_status'] = le.fit_transform(master_df1['order_status'])\n",
    "master_df1['customer_state'] = le.fit_transform(master_df1['customer_state'])\n",
    "master_df1['payment_type'] = le.fit_transform(master_df1['payment_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature  : time it took to deliver \n",
    "master_df1['time_elapsed_delivery'] = master_df1['order_delivered_customer_date'] - master_df1['order_purchase_timestamp']\n",
    "master_df1['time_elapsed_delivery'] = master_df1.time_elapsed_delivery.dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a generic user dataframe to keep CustomerID and new segmentation scores\n",
    "df_user = pd.DataFrame(master_df1['customer_unique_id'])\n",
    "df_user.columns = ['customer_unique_id']\n",
    "\n",
    "#gets the max purchase date for each customer and create a dataframe with it\n",
    "df_max_purchase = master_df1.groupby('customer_unique_id').order_purchase_timestamp.max().reset_index()\n",
    "df_max_purchase.columns = ['customer_unique_id', 'MaxPurchaseDate']\n",
    "\n",
    "#we take our observation point as the max purchase date in our dataset\n",
    "df_max_purchase['Recency'] = (df_max_purchase['MaxPurchaseDate'].max() - df_max_purchase['MaxPurchaseDate']).dt.days\n",
    "\n",
    "#merge this dataframe to our new user dataframe\n",
    "df_user = pd.merge(df_user, df_max_purchase[['customer_unique_id','Recency']], on='customer_unique_id')\n",
    "\n",
    "df_user= df_user.groupby('customer_unique_id').mean().reset_index()\n",
    "\n",
    "#merge it to master df\n",
    "master_df1 = pd.merge(master_df1, df_user, on='customer_unique_id')\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get order counts for each user and create a dataframe with it\n",
    "df_frequency = master_df1.groupby('customer_unique_id').order_purchase_timestamp.count().reset_index()\n",
    "df_frequency.columns = ['customer_unique_id','Frequency']\n",
    "\n",
    "#add this data to our main dataframe\n",
    "master_df1 = pd.merge(master_df1, df_frequency, on='customer_unique_id')\n",
    "master_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## (Unsupervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # selecting numeric columns\n",
    "\"\"\"creating dataframe that has only numeric columns then extract them easy\"\"\"\n",
    "numeric_df = master_df1.select_dtypes(exclude=[object,'datetime'])\n",
    "numeric_columns = list(numeric_df.columns.values)\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['_merge', 'product_height_cm', 'product_width_cm', 'product_length_cm', 'payment_installments', 'order_item_id', 'price', 'month','order_item_id']\n",
    "\n",
    "numeric_list_clean = [element for element in numeric_columns if element not in columns_to_remove]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_list_clean.append('customer_unique_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df1[numeric_list_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Very high level of groupby use ! \n",
    "# we are grouping by customer ids and aggregating every column on what it should be \n",
    "clustering_customers_df = master_df1[numeric_list_clean]\n",
    "clustering_customers_df = clustering_customers_df.groupby('customer_unique_id').agg({ 'review_score': 'mean', 'payment_value':'sum','seller_zip_code_prefix':'max',\n",
    "          'product_weight_g': 'mean','product_photos_qty':'mean',\n",
    "           'product_name_lenght':'mean','Recency':'max','Frequency':'sum'}).reset_index()\n",
    "\n",
    "clustering_customers_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(clustering_customers_df.corr().round(2), xticklabels=clustering_customers_df.corr().columns, yticklabels=clustering_customers_df.corr().columns, cmap='Spectral',vmin=-1, vmax=1, annot=True)\n",
    "\n",
    "plt.title('Corrélations entres les features', fontsize=22)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale numeric columns before K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting numeric columns\n",
    "numeric_df1 = clustering_customers_df.select_dtypes(exclude=[object])\n",
    "num_columns = list(numeric_df1.columns.values)\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#instantiate scaler\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(numeric_df1)\n",
    "data_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing data for T-SNE\n",
    "sliced_data = numeric_df1.sample(10000,random_state=9)\n",
    "sclaed_sliced_data = scaler.transform(sliced_data)\n",
    "sliced_data_df = pd.DataFrame(data = sclaed_sliced_data, columns=sliced_data.columns)\n",
    "sliced_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans\n",
    "kmeans = KMeans(4,random_state=9)\n",
    "kmeans.fit(data_scaled)\n",
    "predicted_df = sliced_data_df.copy()\n",
    "predicted_df['cluster_pred'] = kmeans.predict(sliced_data_df) ## clusters remplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2,init='pca',n_jobs=-1,random_state=9,verbose=1,perplexity=50)\n",
    "data_embedded = tsne.fit_transform(sliced_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "ax = sns.scatterplot(x=data_embedded[:,0], y=data_embedded[:,1], alpha=0.8,\\\n",
    "                x_jitter=0.5, y_jitter=0.5, hue=predicted_df['cluster_pred'],\\\n",
    "                palette=sns.color_palette(\"hls\", n_colors=4));\n",
    "\n",
    "\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='25')\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='20')\n",
    "plt.title('Clustering Customers'.title(), fontsize=20);\n",
    "\n",
    "plt.xticks(rotation=0, fontsize= 12);\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coef shilouaite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silh = []\n",
    "for i in range(2,10):\n",
    "    kmeans = KMeans(i,n_jobs=-1,n_init=1, verbose=3)\n",
    "    kmeans.fit(sliced_data_df)\n",
    "    silhouhaite = silhouette_score(sliced_data_df, kmeans.labels_)\n",
    "    silh.append(silhouhaite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 seems to have a good change in wcss, we will try it.\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "plt.plot(range(2,10), silh, linewidth=4, marker='o');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zezeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Elbow Method to choose the number of clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
